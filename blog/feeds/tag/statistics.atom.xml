<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Graduate Descent</title><link href="http://timvieira.github.io/blog/" rel="alternate"></link><link href="/blog/feeds/tag/statistics.atom.xml" rel="self"></link><id>http://timvieira.github.io/blog/</id><updated>2014-12-21T00:00:00-05:00</updated><entry><title>Importance Sampling</title><link href="http://timvieira.github.io/blog/post/2014/12/21/importance-sampling/" rel="alternate"></link><updated>2014-12-21T00:00:00-05:00</updated><author><name>Tim Vieira</name></author><id>tag:timvieira.github.io/blog,2014-12-21:post/2014/12/21/importance-sampling/</id><summary type="html">&lt;p&gt;Importance sampling is a powerful and pervasive technique in statistics, machine
learning and randomized algorithms.&lt;/p&gt;
&lt;h2&gt;Basics&lt;/h2&gt;
&lt;p&gt;Importance sampling is a technique for estimating the expectation &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; of a
random variable &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt; under distribution &lt;span class="math"&gt;\(p\)&lt;/span&gt; from samples of a different
distribution &lt;span class="math"&gt;\(q\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The key observation is that &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; is can expressed as the expectation of a
different random variable &lt;span class="math"&gt;\(f^*(x)=\frac{p(x)}{q(x)}\! \cdot\! f(x)\)&lt;/span&gt; under &lt;span class="math"&gt;\(q\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
\mathbb{E}_{q}\! \left[ f^*(x) \right] = \mathbb{E}_{q}\! \left[ \frac{p(x)}{q(x)} f(x) \right] = \sum_{x} q(x) \frac{p(x)}{q(x)} f(x) = \sum_{x} p(x) f(x) = \mathbb{E}_{p}\! \left[ f(x) \right] = \mu
$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Technical condition: &lt;span class="math"&gt;\(q\)&lt;/span&gt; must have support everywhere &lt;span class="math"&gt;\(p\)&lt;/span&gt; does, &lt;span class="math"&gt;\(p(x) &amp;gt; 0
\Rightarrow q(x) &amp;gt; 0\)&lt;/span&gt;. Without this condition, the equation is biased! Note: &lt;span class="math"&gt;\(q\)&lt;/span&gt;
can support things that &lt;span class="math"&gt;\(p\)&lt;/span&gt; doesn't.&lt;/p&gt;
&lt;p&gt;Terminology: The quantity &lt;span class="math"&gt;\(w(x) = \frac{p(x)}{q(x)}\)&lt;/span&gt; is often referred to as the
"importance weight" or "importance correction". We often refer to &lt;span class="math"&gt;\(p\)&lt;/span&gt; as the
target density and &lt;span class="math"&gt;\(q\)&lt;/span&gt; the proposal density.&lt;/p&gt;
&lt;p&gt;Now, given samples &lt;span class="math"&gt;\(\{ x^{(i)} \}_{i=1}^{n}\)&lt;/span&gt; from &lt;span class="math"&gt;\(q\)&lt;/span&gt;, we can use the Monte
Carlo estimate, &lt;span class="math"&gt;\(\hat{\mu} \approx \frac{1}{n} \sum_{i=1}^n f^{*}(x^{(i)})\)&lt;/span&gt;, as
an unbiased estimator of &lt;span class="math"&gt;\(\mu\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2&gt;Remarks&lt;/h2&gt;
&lt;p&gt;There are a few reasons we might want use importance sampling:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Convenience&lt;/strong&gt;: It might be trickier to sample directly from &lt;span class="math"&gt;\(p\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bias-correction&lt;/strong&gt;: Suppose, we're developing an algorithm which requires
     samples to satisfy some "safety" condition (e.g., a minimum support
     threshold) and be unbiased. Importance sampling can be used to remove bias,
     while satisfying the condition.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Variance reduction&lt;/strong&gt;: It might be the case that sampling directly from
     &lt;span class="math"&gt;\(p\)&lt;/span&gt; would require more samples to estimate &lt;span class="math"&gt;\(\mu\)&lt;/span&gt;. Check out these
     &lt;a href="http://www.columbia.edu/~mh2078/MCS04/MCS_var_red2.pdf"&gt;great notes&lt;/a&gt; for
     more.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Off-policy evaluation and learning&lt;/strong&gt;: We might want to collect some
     "exploratory data" from &lt;span class="math"&gt;\(q\)&lt;/span&gt; and evaluate different "policies", &lt;span class="math"&gt;\(p\)&lt;/span&gt; (e.g.,
     to pick the best one). Some cool papers:
     &lt;a href="http://arxiv.org/abs/1209.2355"&gt;counterfactual reasoning&lt;/a&gt;,
     &lt;a href="http://arxiv.org/abs/cs/0204043"&gt;reinforcement learning&lt;/a&gt;,
     &lt;a href="http://arxiv.org/abs/1103.4601"&gt;contextual bandits&lt;/a&gt;,
     &lt;a href="http://papers.nips.cc/paper/4156-learning-bounds-for-importance-weighting.pdf"&gt;domain adaptation&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are a few common cases for &lt;span class="math"&gt;\(q\)&lt;/span&gt; worth separate consideration:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Control over &lt;span class="math"&gt;\(q\)&lt;/span&gt;&lt;/strong&gt;: This is the case in experimental design, variance
     reduction, active learning and reinforcement learning. It's often difficult
     to design &lt;span class="math"&gt;\(q\)&lt;/span&gt;, which results in an estimator with "reasonable" variance. A
     very difficult case is in off-policy evaluation because it (essentially)
     requires a good exploratory distribution for every possible policy. (I have
     much more to say on this topic.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Little to no control over &lt;span class="math"&gt;\(q\)&lt;/span&gt;&lt;/strong&gt;: For example, you're given some dataset
     (e.g., new articles) and you want to estimate performance on a different
     dataset (e.g., Twitter).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Unknown &lt;span class="math"&gt;\(q\)&lt;/span&gt;&lt;/strong&gt;: In this case, we want to estimate &lt;span class="math"&gt;\(q\)&lt;/span&gt; (typically referred
     to as the propensity score) and use it in the importance sampling
     estimator. This technique, as far as I can tell, is widely used to remove
     selection bias when estimating effects of different treatments.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Drawbacks&lt;/strong&gt;: The main drawback of importance sampling is variance. A few bad
samples with large weights can drastically throw off the estimator. Thus, it's
often the case that a biased estimator is preferred, e.g.,
&lt;a href="https://hips.seas.harvard.edu/blog/2013/01/14/unbiased-estimators-of-partition-functions-are-basically-lower-bounds/"&gt;estimating the partition function&lt;/a&gt;,
&lt;a href="http://arxiv.org/abs/1209.2355"&gt;clipping weights&lt;/a&gt;,
&lt;a href="http://arxiv.org/abs/cs/0204043"&gt;indirect importance sampling&lt;/a&gt;. A secondary
drawback is that both densities must be normalized, which is often intractable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What's next?&lt;/strong&gt; I plan to cover "variance reduction" and "off-policy
evaluation" in more detail in future posts.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="math"></category><category term="statistics"></category><category term="randomized"></category></entry><entry><title>KL-divergence as an objective function</title><link href="http://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/" rel="alternate"></link><updated>2014-10-06T00:00:00-04:00</updated><author><name>Tim Vieira</name></author><id>tag:timvieira.github.io/blog,2014-10-06:post/2014/10/06/kl-divergence-as-an-objective-function/</id><summary type="html">&lt;p&gt;It's well-known that
&lt;a href="http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"&gt;KL-divergence&lt;/a&gt;
is not symmetric, but which direction is right for fitting your model?&lt;/p&gt;
&lt;p&gt;First, which one is which?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cheat sheet&lt;/strong&gt;: If we're fitting &lt;span class="math"&gt;\(q\)&lt;/span&gt; to &lt;span class="math"&gt;\(p\)&lt;/span&gt; using&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\textbf{KL}(q || p)\)&lt;/span&gt;
  - mode-seeking, exclusive
  - no normalization wrt &lt;span class="math"&gt;\(p\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\textbf{KL}(p || q)\)&lt;/span&gt;
  - mean-seeking, inclusive
  - results in a moment-matching problem when &lt;span class="math"&gt;\(q\)&lt;/span&gt; is in the exponential family
  - requires normalization wrt &lt;span class="math"&gt;\(p\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How I remember which is which&lt;/strong&gt;: The KL notation is a little strange with the
"&lt;span class="math"&gt;\(||\)&lt;/span&gt;". I pretend it's a division symbol. This happens to correspond nicely to a
division symbol in the corresponding equation (I'm not sure it's
intentional). It helps to remember that you always normalize wrt the "numerator"
(and &lt;span class="math"&gt;\(q\)&lt;/span&gt;).&lt;/p&gt;
&lt;h2&gt;Computational perspecive&lt;/h2&gt;
&lt;p&gt;Let's look at what's involved in fitting a model &lt;span class="math"&gt;\(q_\theta\)&lt;/span&gt; in each
direction. In this section, I'll describe the gradient and pay special attention
to the issue of normalization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Notation&lt;/strong&gt;: &lt;span class="math"&gt;\(p,q_\theta\)&lt;/span&gt; are probabilty distributions. &lt;span class="math"&gt;\(p = \bar{p} / Z_p\)&lt;/span&gt;,
where &lt;span class="math"&gt;\(Z_p\)&lt;/span&gt; is the normalization constant. Similarly for &lt;span class="math"&gt;\(q\)&lt;/span&gt;.&lt;/p&gt;
&lt;h3&gt;The easy direction &lt;span class="math"&gt;\(\textbf{KL}(q_\theta || p)\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;
&lt;div class="math"&gt;\begin{align*}
\textbf{KL}(q_\theta || p)
&amp;amp;= \sum_d q(d) \log \left( \frac{q(d)}{p(d)} \right) \\
&amp;amp;= \sum_d q(d) \left( \log q(d) - \log p(d) \right) \\
&amp;amp;= \underbrace{\sum_d q(d) \log q(d)}_{-\text{entropy}} - \underbrace{\sum_d q(d) \log p(d)}_{\text{cross-entropy}} \\
\end{align*}&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Let's look at normalization of &lt;span class="math"&gt;\(p\)&lt;/span&gt;, the entropy term is easy because there is no &lt;span class="math"&gt;\(p\)&lt;/span&gt; in it.
&lt;div class="math"&gt;\begin{align*}
\sum_d q(d) \log p(d)
&amp;amp;= \sum_d q(d) \log (\bar{p}(d) / Z_p) \\
&amp;amp;= \sum_d q(d) \left( \log \bar{p}(d) - \log Z_p) \right) \\
&amp;amp;= \sum_d q(d) \log \bar{p}(d) - \sum_d q(d) \log Z_p \\
&amp;amp;= \sum_d q(d) \log \bar{p}(d) - \log Z_p
\end{align*}&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;In this case, &lt;span class="math"&gt;\(-\log Z_p\)&lt;/span&gt; is an additive constant, which can be dropped because
we're optimizing.&lt;/p&gt;
&lt;p&gt;This leaves us with the following optimization problem:
&lt;div class="math"&gt;\begin{align*}
&amp;amp; \text{argmin}_\theta \textbf{KL}(q_\theta || p) \\
&amp;amp;\qquad = \text{argmin}_\theta \sum_d q_\theta(d) \log q_\theta(d) - \sum_d q_\theta(d) \log \bar{p}(d)
\end{align*}&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Let's work out the gradient
&lt;div class="math"&gt;\begin{align*}
&amp;amp; \nabla\left[ \sum_d q_\theta(d) \log q_\theta(d) - \sum_d q_\theta(d) \log \bar{p}(d) \right] \\
&amp;amp;\qquad = \sum_d \nabla \left[ q_\theta(d) \log q_\theta(d) \right] - \sum_d \nabla\left[ q_\theta(d) \right] \log \bar{p}(d) \\
&amp;amp;\qquad = \sum_d \nabla \left[ q_\theta(d) \right] \left( 1 + \log q_\theta(d) \right) - \sum_d \nabla\left[ q_\theta(d) \right] \log \bar{p}(d) \\
&amp;amp;\qquad = \sum_d \nabla \left[ q_\theta(d) \right] \left( 1 + \log q_\theta(d) - \log \bar{p}(d) \right) \\
&amp;amp;\qquad = \sum_d \nabla \left[ q_\theta(d) \right] \left( \log q_\theta(d) - \log \bar{p}(d) \right) \\
\end{align*}&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;We killed the one in the last equality because &lt;span class="math"&gt;\(\sum_d \nabla
\left[ q(d) \right] = \nabla \left[ \sum_d q(d) \right] = \nabla
\left[ 1 \right] = 0\)&lt;/span&gt;, for any &lt;span class="math"&gt;\(q\)&lt;/span&gt; which is a probability distribution.&lt;/p&gt;
&lt;p&gt;This direction is convenient because we don't need to normalize
&lt;span class="math"&gt;\(p\)&lt;/span&gt;. Unfortunately, the "easy" direction is nonconvex in general --- unlike the
"hard" direction, which is convex.&lt;/p&gt;
&lt;h3&gt;Harder direction &lt;span class="math"&gt;\(\textbf{KL}(p || q_\theta)\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;
&lt;div class="math"&gt;\begin{align*}
\textbf{KL}(p || q_\theta)
&amp;amp;= \sum_d p(d) \log \left( \frac{p(d)}{q(d)} \right) \\
&amp;amp;= \sum_d p(d) \left( \log p(d) - \log q(d) \right) \\
&amp;amp;= \sum_d p(d) \log p(d) - \sum_d p(d) \log q(d) \\
\end{align*}&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Clearly the first term (entropy) won't matter if we're just trying optimize wrt
&lt;span class="math"&gt;\(\theta\)&lt;/span&gt;. So, let's focus on the second term (cross-entropy).
&lt;div class="math"&gt;\begin{align*}
\sum_d p(d) \log q(d)
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \log \left( \bar{q}(d)/Z_q \right) \\
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \log \left( \bar{q}(d)/Z_q \right) \\
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \left( \log \bar{q}(d) - \log Z_q \right) \\
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \log \bar{q}(d) - \frac{1}{Z_p} \sum_d \bar{p}(d) \log Z_q \\
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \log \bar{q}(d) - \log Z_q \frac{1}{Z_p} \sum_d \bar{p}(d) \\
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \log \bar{q}(d) - \log Z_q
\end{align*}&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Unfortunately the &lt;span class="math"&gt;\(Z_p\)&lt;/span&gt; factor is unavoidable. The usual "approximate inference
story" is that &lt;span class="math"&gt;\(Z_p\)&lt;/span&gt; is hard to compute, while the approximating distributions
normalization constant &lt;span class="math"&gt;\(Z_q\)&lt;/span&gt; is easy.&lt;/p&gt;
&lt;p&gt;Nonetheless, optimizing KL in this direction is still useful. Examples include,
expectation propagation, variational decoding, standard maximum likelihood is
even an example (were &lt;span class="math"&gt;\(p\)&lt;/span&gt; is the empirical distribution).&lt;/p&gt;
&lt;p&gt;The gradient, when &lt;span class="math"&gt;\(q\)&lt;/span&gt; is in the exponential family, is intuitive:&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;\begin{align*}
\nabla \left[ \frac{1}{Z_p} \sum_d \bar{p}(d) \log \bar{q}(d) - \log Z_q \right]
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \nabla \left[ \log \bar{q}(d) \right] - \nabla \log Z_q \\
&amp;amp;= \frac{1}{Z_p} \sum_d \bar{p}(d) \phi_q(d) - \mathbb{E}_q \left[ \phi_q \right] \\
&amp;amp;= \mathbb{E}_p \left[ \phi_q \right] - \mathbb{E}_q \left[ \phi_q \right]
\end{align*}&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;Optimization problem is convex for exponential families.&lt;/p&gt;
&lt;p&gt;Computing &lt;span class="math"&gt;\(\mathbb{E}_p \left[ \phi_q \right]\)&lt;/span&gt; might not be tractable.&lt;/p&gt;
&lt;p&gt;You can think of maximum likelihood estimation as a method which minimizes KL
divergence from samples &lt;span class="math"&gt;\(p\)&lt;/span&gt;. In this case, &lt;span class="math"&gt;\(p\)&lt;/span&gt; is the true data distribution!
The first term in the gradient is based on a sample ("observed expected feature
counts").&lt;/p&gt;
&lt;h2&gt;Remarks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Both directions of KL are special cases of &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;-divergence. For a unified
  account of both directions consider looking into &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;-divergence.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inclusive divergences require &lt;span class="math"&gt;\(q &amp;gt; 0\)&lt;/span&gt; whenever &lt;span class="math"&gt;\(p &amp;gt; 0\)&lt;/span&gt;. No "false negatives".&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exclusive divergences will often favor a single mode.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="math"></category><category term="statistics"></category><category term="machine-learning"></category></entry></feed>